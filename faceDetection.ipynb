{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faceDetection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "qbu17W8U4ABn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "import getpass\n",
        "\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "\n",
        "vcode = getpass.getpass()\n",
        "\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "\n",
        "!mkdir -p drive\n",
        "\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q9cos-tpQ9Wg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls drive/ColabNotebooks/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0u7IgbUp4lWZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.sparse import coo_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2-6j5r_z4tp0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters(n_input, n_hidden): # initialize parameters with tiny random numbers\n",
        "    num_of_layers = len(n_hidden)\n",
        "    parameters = {}\n",
        "    \n",
        "    parameters['w1'] = np.random.randn(n_hidden[0], n_input) * np.sqrt(2/n_input)\n",
        "    parameters['b1'] = np.zeros((n_hidden[0], 1))\n",
        "    \n",
        "    for i in range(1, num_of_layers):\n",
        "        parameters['w'+str(i+1)] = np.random.randn(n_hidden[i], n_hidden[i-1]) * np.sqrt(2/n_hidden[i-1])\n",
        "        parameters['b'+str(i+1)] = np.zeros((n_hidden[i], 1))\n",
        "    \n",
        "    parameters['w'+str(num_of_layers+1)] = np.random.randn(1, n_hidden[num_of_layers-1]) * np.sqrt(2/n_hidden[num_of_layers-1])\n",
        "    parameters['b'+str(num_of_layers+1)] = np.zeros((1, 1))\n",
        "\n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jk3V_0ZZQKDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def relu(z):\n",
        "    return np.maximum(z, 0)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    der = np.zeros(z.shape)\n",
        "    der[z >= 0] = 1\n",
        "    return der"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QW-sZthL40F7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def forward_prop(x, parameters, activation, keep_prob=1.0):\n",
        "    cache = {}\n",
        "    last_layer = len(parameters) // 2\n",
        "    cache['a'+str(0)] = x\n",
        "    \n",
        "    for l in range(1, last_layer+1):\n",
        "        cache['z'+str(l)] = np.dot(parameters['w'+str(l)], cache['a'+str(l-1)]) + parameters['b'+str(l)]\n",
        "        if l == last_layer: \n",
        "            cache['a'+str(last_layer)] = 1/(1 + np.exp(-cache['z'+str(last_layer)]))\n",
        "        elif activation == 'relu':\n",
        "            cache['a'+str(l)] = relu(cache['z'+str(l)])\n",
        "        elif activation == 'sigmoid': \n",
        "            cache['a'+str(l)] = 1/(1 + np.exp(-cache['z'+str(l)]))\n",
        "        elif activation == 'tanh': \n",
        "            cache['a'+str(l)] = np.tanh(cache['z'+str(l)])\n",
        "        \n",
        "        if keep_prob != 1.0 and l != last_layer:\n",
        "            dropout_temp = np.random.randn(cache['a'+str(l)].shape[0], cache['a'+str(l)].shape[1]) < keep_prob\n",
        "            cache['dropout_vec'+str(l)] = dropout_temp \n",
        "            cache['a'+str(l)] = np.multiply(cache['a'+str(l)], dropout_temp) / keep_prob\n",
        "\n",
        "    return cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WuubFzLY42uO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def back_prop(x, y, cache, parameters, activation, _lambda, keep_prob):\n",
        "    m = x.shape[1]\n",
        "    gradients = {}\n",
        "    last_layer = len(parameters) // 2\n",
        "\n",
        "    gradients['dz'+str(last_layer)] = cache['a'+str(last_layer)] - y.T\n",
        "    gradients['dw'+str(last_layer)] = 1/m * np.dot(gradients['dz'+str(last_layer)], cache['a'+str(last_layer-1)].T) + _lambda/m * parameters['w'+str(last_layer)]\n",
        "    gradients['db'+str(last_layer)] = 1/m * np.sum(gradients['dz'+str(last_layer)], axis=1, keepdims=True)\n",
        "        \n",
        "    for i in reversed(range(1, last_layer)):\n",
        "        dA = np.dot(parameters['w'+str(i+1)].T, gradients['dz'+str(i+1)])\n",
        "        if keep_prob != 1.0 and i != last_layer:\n",
        "            dA *= cache['dropout_vec'+str(i)]\n",
        "            dA /= keep_prob\n",
        "            \n",
        "        if activation == 'sigmoid': \n",
        "            sigmoid = 1/(1 + np.exp(-cache['z'+str(i)]))\n",
        "            gradients['dz'+str(i)] = dA * (sigmoid * (1 - sigmoid))\n",
        "        elif activation == 'relu':\n",
        "            gradients['dz'+str(i)] = dA * relu_derivative(cache['z'+str(i)])\n",
        "        elif activation == 'tanh': \n",
        "            gradients['dz'+str(i)] = dA * (1 - np.power(np.tanh(cache['z'+str(i)]), 2))\n",
        "     \n",
        "        gradients['dw'+str(i)] = 1/m * np.dot(gradients['dz'+str(i)], cache['a'+str(i-1)].T) + _lambda/m * parameters['w'+str(i)]\n",
        "        gradients['db'+str(i)] = 1/m * np.sum(gradients['dz'+str(i)], axis=1, keepdims=True)\n",
        "    \n",
        "    return gradients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ZxmAytDQKEF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cost_function(m, labels, y_hat, params, lambd): # regularized\n",
        "    last_layer = len(params) // 2\n",
        "    return -1/m * (np.sum(labels * np.log(y_hat)) + np.sum((1-labels) * np.log(1 - y_hat))) + lambd/(2*m) * np.sum([\n",
        "            np.power(np.linalg.norm(params['w'+str(i)]), 2) for i in range(1, last_layer+1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DXavV7dnzMlI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_weights(num):\n",
        "    parameters = {}\n",
        "    for i in range(1, num+1):\n",
        "        parameters[\"w\"+str(i)] = np.load(\"w\"+str(i)+\".npy\")\n",
        "        parameters[\"b\"+str(i)] = np.load(\"b\"+str(i)+\".npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PSEIPO6845Zr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def multi_Layer_NN(samples, labels, n_hidden, num_iterations, batch_size=None, load_last_weights=0, activation=\"tanh\", learning_rate=0.01, _lambda=0, keep_prob_dropout=1.0, print_cost=False):\n",
        "    m = samples.shape[1]\n",
        "    if not batch_size:\n",
        "       batch_size = m\n",
        "    \n",
        "    if load_last_weights == 0:\n",
        "       params = initialize_parameters(samples.shape[0], n_hidden)\n",
        "    else:\n",
        "       params = load_weights(load_last_weights)       \n",
        "    \n",
        "    cost_history = []\n",
        "    last_layer = len(params) // 2\n",
        "    \n",
        "    for i in range(1, num_iterations+1):\n",
        "        \n",
        "        for t in range(math.ceil(m/batch_size)):\n",
        "            \n",
        "            cache = forward_prop(samples[:, int(t*batch_size):int((t+1)*batch_size)], params, activation, keep_prob_dropout)\n",
        "            \n",
        "            gradients = back_prop(samples[:, int(t*batch_size):int((t+1)*batch_size)],\n",
        "                                  labels[int(t*batch_size):int((t+1)*batch_size)], \n",
        "                                  cache, \n",
        "                                  params, \n",
        "                                  activation, \n",
        "                                  _lambda, \n",
        "                                  keep_prob_dropout)\n",
        "            \n",
        "            for j in range(1, last_layer+1):\n",
        "                params['w'+str(j)] -= learning_rate * gradients['dw'+str(j)]\n",
        "                params['b'+str(j)] -= learning_rate * gradients['db'+str(j)]\n",
        "             \n",
        "            if print_cost: \n",
        "                cost = cost_function(batch_size, labels[int(t*batch_size):int((t+1)*batch_size)], cache['a'+str(last_layer)].T, params, _lambda)\n",
        "                print('cost after epoch {}: {}'.format(int(i), cost))\n",
        "                cost_history.append(cost)\n",
        "              \n",
        "    return {'parameters':params, \n",
        "            'cache': cache,\n",
        "            'cost_history':cost_history\n",
        "           }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "my_b07jt49FW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(x, parameters, activation):\n",
        "    last_layer = len(parameters) // 2\n",
        "    cache = forward_prop(x.T, parameters, activation)\n",
        "    y_hat = cache['a'+str(last_layer)]\n",
        "    y_hat[y_hat >= 0.5] = 1\n",
        "    y_hat[y_hat < 0.5] = 0\n",
        "\n",
        "    return y_hat.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AfmbWYkWQKEv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## load dataset section"
      ]
    },
    {
      "metadata": {
        "id": "Sa79EdngQKEz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "samples = scipy.io.loadmat('drive/ColabNotebooks/olivettifaces.mat')\n",
        "samples = samples['faces'].T\n",
        "labels = np.ones((samples.shape[0], 1))\n",
        "artificialZeroData = np.random.randint(0, 256, (samples.shape[0], samples.shape[1]))\n",
        "artificialZeroLabel = np.zeros((artificialZeroData.shape[0], 1))\n",
        "samples = np.vstack((samples, artificialZeroData))\n",
        "labels = np.vstack((labels, artificialZeroLabel))\n",
        "\n",
        "_mean = np.mean(samples, axis=1).reshape(-1, 1)\n",
        "variance = (np.std(samples, axis=1)**2).reshape(-1, 1)\n",
        "samples = (samples - _mean)/variance\n",
        "\n",
        "samples_sparse = coo_matrix(samples)\n",
        "samples, samples_sparse, labels = shuffle(samples, samples_sparse, labels)\n",
        "\n",
        "train_data, test_data, train_label, test_label = train_test_split(samples, labels, test_size=0.30, random_state=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pxDTquG5QKE8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(samples.shape, labels.shape)\n",
        "print(train_data.shape, train_label.shape)\n",
        "print(test_data.shape, test_label.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z9IH-_NnQKFP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## train section"
      ]
    },
    {
      "metadata": {
        "id": "ycSNfwRy4-3_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tic = time.time()\n",
        "activation_function = 'tanh'\n",
        "model = multi_Layer_NN(train_data.T,\n",
        "                         train_label,\n",
        "                         activation=activation_function,\n",
        "                         n_hidden=[100, 100, 100],\n",
        "                         num_iterations=500,\n",
        "                         batch_size=64,\n",
        "                         learning_rate=0.1,\n",
        "                         _lambda = 0,\n",
        "                         keep_prob_dropout= 1,\n",
        "                         print_cost=True)\n",
        "\n",
        "print(\"Train phase time:\", time.time()-tic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uRyJCdQeQKFd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_labels = predict(train_data, parameters=model['parameters'], activation=activation_function)\n",
        "print('accuracy on train set:', (np.sum(pred_labels == train_label)/pred_labels.size) * 100, '%')\n",
        "pred_labels = predict(test_data, parameters=model['parameters'], activation=activation_function)\n",
        "print('accuracy on test set:', (np.sum(pred_labels == test_label)/pred_labels.size) * 100, '%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bqy13PV_QKFq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### plot cost value"
      ]
    },
    {
      "metadata": {
        "id": "1SwQdN-zQKFw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(model['cost_history'])), model['cost_history'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i5OuzRIEQKF5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### test an example of test set"
      ]
    },
    {
      "metadata": {
        "id": "_2H7x-w_QKF8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "photo_number = 15\n",
        "imgplot = plt.imshow(test_data[photo_number].reshape(64, 64))\n",
        "plt.show()\n",
        "pred_labels = predict(test_data[photo_number].reshape(1, -1), parameters=model['parameters'], activation=activation_function)\n",
        "print(pred_labels)\n",
        "if int(pred_labels[0][0]) == 1:\n",
        "    print('Human')\n",
        "else:\n",
        "    print('Not-Human')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zFX6wwPvQbcY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save the model in files"
      ]
    },
    {
      "metadata": {
        "id": "nav0_CuqySGQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_weights(parameters):\n",
        "    for i in range(1, (len(parameters)//2)+1):\n",
        "        np.save(\"drive/ColabNotebooks/w\"+str(i), parameters['w'+str(i)])\n",
        "        np.save(\"drive/ColabNotebooks/b\"+str(i), parameters['b'+str(i)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kn1AF7RiQmYM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_weights(model['parameters'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BVy0VYQHQKGS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### predict an example from you\n",
        "It must be a 64*64 photo."
      ]
    },
    {
      "metadata": {
        "id": "DNbgpqVuQKGX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# myimg = mpimg.imread('myimg.jpg')\n",
        "# imgplot = plt.imshow(myimg)\n",
        "# print(myimg.shape)\n",
        "\n",
        "def predict_new_photo(photo_name):\n",
        "    # import photo and convert it to greyscale 64*64\n",
        "    x=Image.open(photo_name, 'r')\n",
        "    x=x.convert('L') #makes it greyscale\n",
        "    y=np.asarray(x.getdata(), dtype=np.float64).reshape((x.size[1],x.size[0]))\n",
        "    y=np.asarray(y, dtype=np.uint8) #if values still in range 0-255! \n",
        "    w=Image.fromarray(y,mode='L')\n",
        "    w.save('out.jpg')\n",
        "\n",
        "    # rotate imgae 90 degree\n",
        "    raw_img = Image.open(\"out.jpg\")\n",
        "    img = raw_img.rotate(90)\n",
        "    # img.show()\n",
        "    img.save(\"out.jpg\")\n",
        "\n",
        "    myimg = mpimg.imread('out.jpg')\n",
        "    imgplot = plt.imshow(myimg)\n",
        "\n",
        "    pred_labels = predict(myimg.reshape(1, -1), parameters=model['parameters'], activation=activation_function)\n",
        "    if int(pred_labels[0][0]) == 1:\n",
        "        print('Human')\n",
        "    else:\n",
        "        print('Not-Human')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IbpzlDuuQKGu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = 6\n",
        "plt.subplot(m,1, 1)\n",
        "predict_new_photo('drive/ColabNotebooks/myimg.jpg')\n",
        "plt.subplot(m,1, 2)\n",
        "predict_new_photo('drive/ColabNotebooks/myimg2.jpg')\n",
        "plt.subplot(m,1, 3)\n",
        "predict_new_photo('drive/ColabNotebooks/myimg3.jpg')\n",
        "plt.subplot(m,1, 4)\n",
        "predict_new_photo('drive/ColabNotebooks/myimg4.jpg')\n",
        "plt.subplot(m,1, 5)\n",
        "predict_new_photo('drive/ColabNotebooks/myimg6.jpg')\n",
        "plt.subplot(m,1, 6)\n",
        "predict_new_photo('drive/ColabNotebooks/myimg5.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LGDvIoZnQKHB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### run a package with the same parameters to check it"
      ]
    },
    {
      "metadata": {
        "id": "g1fjZOZA5AqC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(200, 500, 200), activation='tanh', solver='sgd', alpha=0, learning_rate_init=0.1, max_iter=10000)\n",
        "clf.fit(train_data, train_label)\n",
        "\n",
        "print('accuracy on train set:', clf.score(train_data, train_label)*100)\n",
        "print('accuracy on test set:', clf.score(test_data, test_label)*100)\n",
        "print('loss:', clf.loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q09xchUWQKHT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "myimg = mpimg.imread('out.jpg')\n",
        "print(clf.predict(myimg.reshape(1, -1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1zlTvK1bQKHo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}